y <- X %*% beta + rnorm(n)
data <- data.frame(y, X)
bestlambda <- best_lambda(formula = y ~ .,
data = data, nfold = 5, intercept = FALSE,
lambda_list = 10^seq(-2, 2, by = .1))
betahat <- as.numeric(ridge_regression(formula = y ~ .,
data = data, intercept = FALSE,
lambda = bestlambda)$coefficients)
return(sqrt(sum((betahat - beta)^2)))
}
ridge_error(X = X)
ridge_error <- function(X) {
y <- X %*% beta + rnorm(n)
data <- data.frame(y, X)
bestlambda <- best_lambda(formula = y ~ .,
data = data, nfold = 5, intercept = FALSE,
lambda_list = 10^seq(-2, 2, by = .1))
betahat <- as.numeric(ridge_regression(formula = y ~ .,
data = data, intercept = FALSE,
lambda = bestlambda)$coefficients)
return(sqrt(sum((betahat - beta)^2)))
}
ridge_error(X = X)
replicate(10, ridge_error(X = X))
ridge_error <- function(X) {
y <- X %*% beta + rnorm(n)
data <- data.frame(y, X)
bestlambda <- best_lambda(formula = y ~ .,
data = data, nfold = 5, intercept = FALSE,
lambda_list = 10^seq(-2, 2, by = .1))
betahat <- as.numeric(ridge_regression(formula = y ~ .,
data = data, intercept = FALSE,
lambda = bestlambda)$coefficients)
return(sqrt(sum((betahat - beta)^2)))
}
mean(replicate(100, ridge_error(X = X)))
X
nrow(X)
X %*% beta + rnorm(nrow(X))
ols_error <- function(X, beta) {
# Randomly generate y based on X
y <- X %*% beta + rnorm(nrow(X))
# Use casl package to solve for betahat with svd
betahat <- casl_ols_svd(X, y)
# Calculate RMSE for betahat
return(sqrt(sum((betahat - beta)^2)))
}
ridge_error <- function(X, beta) {
# Randomly generate y based on X
y <- X %*% beta + rnorm(nrow(X))
data <- data.frame(y, X)
# Use my bis557 package to solve for betahat with ridge regression
# Use cross-validated best lambda to solve for betahat
bestlambda <- best_lambda(formula = y ~ .,
data = data, nfold = 5, intercept = FALSE,
lambda_list = 10^seq(-2, 2, by = .1))
betahat <- as.numeric(ridge_regression(formula = y ~ .,
data = data, intercept = FALSE,
lambda = bestlambda)$coefficients)
# Calculate RMSE for betahat
return(sqrt(sum((betahat - beta)^2)))
}
# Create a numerically stable X with 1000 rows and 25 columns
set.seed(2019)
X <- matrix(rnorm(1000 * 25), ncol = 25)
# Set the first coordinate of true beta to 1
beta <- c(1, rep(0, 25 - 1))
# Replicate the trial 100 times and report the average RMSE
mean(replicate(100, ols_error(X = X, beta = beta)))
# Replace the first column of X with a collinear column
# This creates a numerically unstable X
X[,1] <- X[,1] * 0.001 + X[,2] * (1 - 0.001)
# Replicate the OLS trial 100 times and report the average RMSE
mean(replicate(100, ols_error(X = X, beta = beta)))
179%%5
floor(179/5)
iris2 <- data(iris)
names(iris2)
head(iris2)
iris2
data(iris)
iris_c <- iris
head(iris_c)
iris_c[ ,3]
# Make Sepal.Width a linear combination of itself and Petal.Length
iris_c[ ,2] <- iris_c[ ,2] * 0.001 + iris_c[ ,3] * (1 - 0.001)
head(iris_c)
as.numeric(ridge_regression(formula = Sepal.Length ~ .,
data = iris_c,
lambda = 0.13)$coefficients)
iris_c <- iris
# Make Sepal.Width a linear combination of itself and Petal.Length
iris_c[ ,2] <- iris_c[ ,2] * 0.001 + iris_c[ ,3] * (1 - 0.001)
my_ridge <- as.numeric(ridge_regression(formula = Sepal.Length ~ .,
data = iris_c,
lambda = 0.13)$coefficients)
my_ridge
X <- model.matrix(Sepal.Length ~ ., iris_c)
y <- as.matrix(iris_c$Sepal.Length)
casl_ridge <-  as.numeric(casl_lm_ridge(X, y, lambda = 0.13))
expect_equivalent(my_ridge, casl_ridge, tolerance = 1e-5)
casl_ridge
best_lambda(formula = Sepal.Length ~ ., data = iris_c, lambda_list = 10^seq(-2, 2, by = .1))
my_ridge <- as.numeric(ridge_regression(formula = Sepal.Length ~ .,
data = iris_c,
lambda = 0.08)$coefficients)
X <- model.matrix(Sepal.Length ~ ., iris_c)
y <- as.matrix(iris_c$Sepal.Length)
casl_ridge <-  as.numeric(casl_lm_ridge(X, y, lambda = 0.08))
my_ridge
casl_ridge
library(bis557)
browseVignettes("packagename")
browseVignettes("bis557")
library(bis557)
browseVignettes("bis557")
browseVignettes("homework-2")
browseVignettes("bis557")
vignette(all = FALSE)
browseVignettes("dplyr")
browseVignettes("bis557")
devtools::build_vignettes()
browseVignettes("bis557")
library(bis557)
browseVignettes("bis557")
devtools::build_vignettes("bis557")
library(bis557)
library(casl)
# Create a numerically stable X with 1000 rows and 25 columns
set.seed(2019)
X <- matrix(rnorm(1000 * 25), ncol = 25)
svals <- svd(crossprod(X))$d
max(svals) / min(svals)
# Set the first coordinate of true beta to 1
beta <- c(1, rep(0, 25 - 1))
# Replicate the OLS trial 100 times and report the average RMSE
mean(replicate(100, ols_error(X = X, beta = beta)))
# Replace the first column of X with a collinear column
# This creates a numerically unstable X
X[ ,1] <- X[ ,1] * 0.001 + X[ ,2] * (1 - 0.001)
svals <- svd(crossprod(X))$d
max(svals) / min(svals)
library(bis557)
library(bis557)
?best_lambda
devtools::build_vignettes()
ridge_regression(formula = Sepal.Length ~ ., data = iris, lambda = 1.8)
library("bis557", lib.loc="~/Library/R/3.5/library")
browseVignettes("bis557")
library("bis557", lib.loc="~/Library/R/3.5/library")
ridge_regression(formula = Sepal.Length ~ ., data = iris, lambda = 1.8)
best_lambda(formula = Sepal.Length ~ .,  data = iris, nfold = 5, lambda_list = 10^seq(-2, 2, by = .1))
ridge_regression(formula = Sepal.Length ~ ., data = iris, lambda = 1.8)
library(bis557)
devtools::build_vignettes()
library(bis557)
library(casl)
# X is the same collinear design matrix from the last chunk
mean(replicate(25, ridge_error(X = X, beta = beta)))
best_lambda(formula = Sepal.Length ~ ., data = iris, nfold = 5, lambda_list = 10^seq(-2, 2, by = .1))
best_lambda(formula = mpg ~ drat + wt + qsec, data = mtcars, nfold = 3, lambda_list = 10^seq(-2, 2, by = .1))
ridge_regression(formula = Sepal.Length ~ ., data = iris, lambda = 1.8)
class(ridge_regression(formula = Sepal.Length ~ ., data = iris, lambda = 1.8))
library(bis557)
devtools::build_vignettes("bis557")
devtools::build_vignettes()
library("casl", lib.loc="~/Library/R/3.5/library")
?casl_lm_ridge
ridge_regression(formula = Sepal.Length ~ ., data = iris, lambda = 5)
# Use the output from casl_ridge as the reference
X <- model.matrix(Sepal.Length ~ ., iris)
y <- as.matrix(iris$Sepal.Length)
as.numeric(casl_lm_ridge(X, y, lambda = 5))
iris_c <- iris
# Make Sepal.Width a linear combination of itself and Petal.Length
iris_c[ ,2] <- iris_c[ ,2] * 0.001 + iris_c[ ,3] * (1 - 0.001)
my_ridge <- as.numeric(ridge_regression(formula = Sepal.Length ~ .,
data = iris_c,
lambda = 0.08)$coefficients)
my_ridge
lm.ridge(Sepal.Length ~ ., iris_c, lambda = 0.08)
library(MASS)
lm.ridge(Sepal.Length ~ ., iris_c, lambda = 0.08)
as.numeric(lm.ridge(Sepal.Length ~ ., iris_c, lambda = 0.08))
set.seed(2019)
X <- matrix(rnorm(1000 * 25), ncol = 25)
X[ ,1] <- X[ ,1] * 0.001 + X[ ,2] * (1 - 0.001)
beta <- c(1, rep(0, 25 - 1))
y <- X %*% beta + rnorm(nrow(X))
y
data <- data.frame(X, y)
data
my_ridge <- as.numeric(ridge_regression(formula = y ~ .,
data = data, intercept = FALSE,
lambda = 0.08)$coefficients)
my_ridge
set.seed(2019)
X <- matrix(rnorm(1000 * 5), ncol = 5)
X[ ,1] <- X[ ,1] * 0.001 + X[ ,2] * (1 - 0.001)
beta <- c(1, rep(0, 5 - 1))
y <- X %*% beta + rnorm(nrow(X))
data <- data.frame(X, y)
my_ridge <- as.numeric(ridge_regression(formula = y ~ .,
data = data, intercept = FALSE,
lambda = 0.08)$coefficients)
my_ridge
my_ridge <- as.numeric(ridge_regression(formula = y ~ .,
data = data,
lambda = 0.08)$coefficients)
my_ridge
lm.ridge(y ~., data)
lm.ridge(y ~., data, lambda = 0.08)
my_ridge
lm.ridge(y ~., data, lambda = 0.08)
library("bis557", lib.loc="~/Library/R/3.5/library")
browseVignettes("bis557")
set.seed(1234)
X <- matrix(rnorm(1000 * 5), ncol = 5)
X[ ,1] <- X[ ,1] * 0.001 + X[ ,2] * (1 - 0.001)
beta <- c(1, rep(0, 5 - 1))
y <- X %*% beta + rnorm(nrow(X))
data <- data.frame(X, y)
my_ridge <- as.numeric(ridge_regression(formula = y ~ .,
data = data,
lambda = 0.08)$coefficients)
lm.ridge(y ~., data, lambda = 0.08)
my_ridge
set.seed(123)
X <- matrix(rnorm(1000 * 5), ncol = 5)
X[ ,1] <- X[ ,1] * 0.001 + X[ ,2] * (1 - 0.001)
beta <- c(1, rep(0, 5 - 1))
set.seed(123)
y <- X %*% beta + rnorm(nrow(X))
data <- data.frame(X, y)
my_ridge <- as.numeric(ridge_regression(formula = y ~ .,
data = data,
lambda = 0.08)$coefficients)
lm.ridge(y ~., data, lambda = 0.08)
my_ridge
set.seed(2019)
X <- matrix(rnorm(1000 * 5), ncol = 5)
X[ ,1] <- X[ ,1] * 0.001 + X[ ,2] * (1 - 0.001)
beta <- c(1, rep(0, 5 - 1))
set.seed(2019)
y <- X %*% beta + rnorm(nrow(X))
data <- data.frame(X, y)
my_ridge <- as.numeric(ridge_regression(formula = y ~ .,
data = data,
lambda = 0.08)$coefficients)
lm.ridge(y ~., data, lambda = 0.08)
my_ridge
set.seed(2019)
X <- matrix(rnorm(1000 * 5), ncol = 5)
X[ ,1] <- X[ ,1] * 0.001 + X[ ,2] * (1 - 0.001)
beta <- c(1, rep(0, 5 - 1))
set.seed(1)
y <- X %*% beta + rnorm(nrow(X))
data <- data.frame(X, y)
my_ridge <- as.numeric(ridge_regression(formula = y ~ .,
data = data,
lambda = 0.08)$coefficients)
lm.ridge(y ~., data, lambda = 0.08)
my_ridge
set.seed(2)
X <- matrix(rnorm(1000 * 5), ncol = 5)
X[ ,1] <- X[ ,1] * 0.001 + X[ ,2] * (1 - 0.001)
beta <- c(1, rep(0, 5 - 1))
set.seed(1)
y <- X %*% beta + rnorm(nrow(X))
data <- data.frame(X, y)
my_ridge <- as.numeric(ridge_regression(formula = y ~ .,
data = data,
lambda = 0.08)$coefficients)
lm.ridge(y ~., data, lambda = 0.08)
my_ridge
best_lambda(formula = y ~ .,
data = data, nfold = 5,
lambda_list = 10^seq(-2, 2, by = .1))
my_ridge <- as.numeric(ridge_regression(formula = y ~ .,
data = data,
lambda = 0.01)$coefficients)
lm_ridge <- lm.ridge(y ~., data, lambda = 0.01)
my_ridge
lm_ridge
set.seed(2)
X <- matrix(rnorm(1000 * 5), ncol = 5)
X[ ,1] <- X[ ,1] * 0.001 + X[ ,2] * (1 - 0.001)
beta <- c(1, rep(0, 5 - 1))
set.seed(1)
y <- X %*% beta + rnorm(nrow(X))
data <- data.frame(X, y)
best_lambda(formula = y ~ .,
data = data, nfold = 5,
lambda_list = 10^seq(-2, 2, by = .1))
my_ridge <- as.numeric(ridge_regression(formula = y ~ .,
data = data,
lambda = 0.08)$coefficients)
lm_ridge <- lm.ridge(y ~., data, lambda = 0.08)
my_ridge
lm_ridge
set.seed(2)
X <- matrix(rnorm(1000 * 5), ncol = 5)
X[ ,1] <- X[ ,1] * 0.001 + X[ ,2] * (1 - 0.001)
beta <- c(1, rep(0, 5 - 1))
set.seed(1)
y <- X %*% beta + rnorm(nrow(X))
data <- data.frame(X, y)
my_ridge <- as.numeric(ridge_regression(formula = y ~ .,
data = data,
lambda = 0.08)$coefficients)
# Use lm.ridge from MASS library as the reference
lm_ridge <- lm.ridge(y ~., data, lambda = 0.08)
my_ridge
lm_ridge
set.seed(2)
X <- matrix(rnorm(1000 * 5), ncol = 3)
X[ ,1] <- X[ ,1] * 0.001 + X[ ,2] * (1 - 0.001)
beta <- c(1, rep(0, 3 - 1))
set.seed(1)
y <- X %*% beta + rnorm(nrow(X))
data <- data.frame(X, y)
data
set.seed(2)
X <- matrix(rnorm(1000 * 5), ncol = 3)
X[ ,1] <- X[ ,1] * 0.001 + X[ ,2] * (1 - 0.001)
beta <- c(1, rep(0, 3 - 1))
set.seed(1)
y <- X %*% beta + rnorm(nrow(X))
data <- data.frame(X, y)
data
my_ridge <- as.numeric(ridge_regression(formula = y ~ .,
data = data,
lambda = 0.08)$coefficients)
# Use lm.ridge from MASS library as the reference
lm_ridge <- lm.ridge(y ~., data, lambda = 0.08)
my_ridge
lm_ridge
# Generate a data with collinear X
set.seed(2)
X <- matrix(rnorm(1000 * 5), ncol = 5)
X[ ,1] <- X[ ,1] * 0.001 + X[ ,2] * (1 - 0.001)
beta <- c(1, rep(0, 5 - 1))
set.seed(1)
y <- X %*% beta + rnorm(nrow(X))
data <- data.frame(X, y)
data
my_ridge <- as.numeric(ridge_regression(formula = y ~ .,
data = data,
lambda = 0.08)$coefficients)
# Use lm.ridge from MASS library as the reference
lm_ridge <- lm.ridge(y ~., data, lambda = 0.08)
lm_ridge
my_ridge
expect_equivalent(my_ridge, lm_ridge, tolerance = 0.5)
library(testthat)
expect_equivalent(my_ridge, lm_ridge, tolerance = 0.5)
as.numeric(lm.ridge(y ~., data, lambda = 0.08))
unlist(lm.ridge(y ~., data, lambda = 0.08))
as.numeric(ridge_regression(formula = y ~ .,
data = data,
lambda = 0.08)$coefficients)
unlist(lm.ridge(y ~., data, lambda = 0.08))[1:6]
my_ridge <- as.numeric(ridge_regression(formula = y ~ .,
data = data,
lambda = 0.08)$coefficients)
# Use lm.ridge from MASS library as the reference
lm_ridge <- as.numeric(unlist(lm.ridge(y ~., data, lambda = 0.08))[1:6])
my_ridge
lm_ridge
lm.ridge(y ~., data, lambda = 0.08))[1:6]
lm.ridge(y ~., data, lambda = 0.08
)
# Use lm.ridge from MASS library as the reference
lm_ridge <- lm.ridge(y ~., data, lambda = 0.08)
lm_ridge
class(lm_ridge)
unlist(lm_ridge)
my_ridge
as.numeric(lm_ridge)
as.numeric(unlist(lm_ridge))
lm_ridge$coef
my_ridge
lm_ridge
lm_ridge$scales
lm_ridge$coef
my_ridge[[1]]
my_ridge[1]
my_ridge[1:6]
lm_ridge[1:6]
X
my_ridge <- as.numeric(ridge_regression(formula = y ~ .,
data = data, intercept = FALSE
lambda = 0.08)$coefficients)
my_ridge <- as.numeric(ridge_regression(formula = y ~ .,
data = data, intercept = FALSE
lambda = 0.08)$coefficients)
my_ridge <- as.numeric(ridge_regression(formula = y ~ .,
data = data, intercept = FALSE,
lambda = 0.08)$coefficients)
as.numeric(ridge_regression(formula = y ~ .,
data = data, intercept = FALSE,
lambda = 0.08)$coefficients)
lm_ridge
my_ridge <- as.numeric(ridge_regression(formula = y ~ .,
data = data, intercept = FALSE,
lambda = 0.08)$coefficients)
my_ridge
lm.ridge(y ~., data, lambda = 0.08)
lm_ridge <- lm.ridge(y ~., data, lambda = 0.08)
lm_ridge$coef
lm.ridge(y ~. -1, data, lambda = 0.08)
my_ridge
set.seed(2)
X <- matrix(rnorm(1000 * 5), ncol = 5)
X[ ,1] <- X[ ,1] * 0.001 + X[ ,2] * (1 - 0.001)
beta <- c(1, rep(0, 5 - 1))
set.seed(1)
y <- X %*% beta + rnorm(nrow(X))
data <- data.frame(X, y)
my_ridge <- as.numeric(ridge_regression(formula = y ~ .,
data = data, intercept = FALSE,
lambda = 0.08)$coefficients)
# Use lm.ridge from MASS library as the reference
lm_ridge <- lm.ridge(y ~. -1, data, lambda = 0.08)
MASSoutput <- unlist(lm_ridge$coef)
lm_ridge
MASSoutput
expect_equivalent(my_ridge, lm_ridge, tolerance = 0.5)
expect_equivalent(my_ridge, MASSoutput, tolerance = 0.5)
set.seed(2019)
X <- matrix(rnorm(1000 * 5), ncol = 5)
X[ ,1] <- X[ ,1] * 0.001 + X[ ,2] * (1 - 0.001)
beta <- c(1, rep(0, 5 - 1))
set.seed(2019)
y <- X %*% beta + rnorm(nrow(X))
data <- data.frame(X, y)
my_ridge <- as.numeric(ridge_regression(formula = y ~ .,
data = data, intercept = FALSE,
lambda = 0.08)$coefficients)
# Use lm.ridge from MASS library as the reference
lm_ridge <- lm.ridge(y ~. -1, data, lambda = 0.08)
MASSoutput <- unlist(lm_ridge$coef)
MASSoutput
lm_ridge
my_ridge <- as.numeric(ridge_regression(formula = y ~ .,
data = data, intercept = FALSE,
lambda = 0.01)$coefficients)
# Use lm.ridge from MASS library as the reference
lm_ridge <- lm.ridge(y ~. -1, data, lambda = 0.01)
MASSoutput <- unlist(lm_ridge$coef)
MASSoutput
lm_ridge
library(bis557)
devtools::build_vignettes()
lm.ridge(y ~. -1, data, lambda = 10^seq(-2, 2, by = .1))
out <- lm.ridge(y ~. -1, data, lambda =  10^seq(-2, 2, by = .1))
out$lambda
out$GCV
min(out$GCV)
which.min(out$GCV)
best_lambda(formula = y ~ ., lambda_list = 10^seq(-2, 2, by = .1),
data = data, intercept = FALSE)
10^seq(-2, 2, by = .1)
# Use lm.ridge from MASS library as the reference
out <- lm.ridge(y ~. -1, data, lambda =  10^seq(-2, 2, by = .1))
which.min(out$GCV)
as.numeric(which.min(out$GCV))
names(which.min(out$GCV))
as.numeric(names(which.min(out$GCV)))
lm_ridge_best <- as.numeric(names(which.min(out$GCV)))
set.seed(2)
X <- matrix(rnorm(1000 * 5), ncol = 5)
X[ ,1] <- X[ ,1] * 0.001 + X[ ,2] * (1 - 0.001)
beta <- c(1, rep(0, 5 - 1))
set.seed(1)
y <- X %*% beta + rnorm(nrow(X))
data <- data.frame(X, y)
my_lambda <- best_lambda(formula = y ~ ., lambda_list = 10^seq(-2, 2, by = .1),
data = data, intercept = FALSE)
my_lambda
out <- lm.ridge(y ~. -1, data, lambda =  10^seq(-2, 2, by = .1))
lm_ridge_best <- as.numeric(names(which.min(out$GCV)))
lm_ridge_best
set.seed(2)
X <- matrix(rnorm(1000 * 5), ncol = 5)
X[ ,1] <- X[ ,1] * 0.001 + X[ ,2] * (1 - 0.001)
beta <- c(1, rep(0, 5 - 1))
set.seed(1)
y <- X %*% beta + rnorm(nrow(X))
data <- data.frame(X, y)
my_lambda <- best_lambda(formula = y ~ ., lambda_list = 10^seq(-2, 2, by = .1),
data = data, intercept = FALSE)
# Use lm.ridge from MASS library as the reference
out <- lm.ridge(y ~. -1, data, lambda =  10^seq(-2, 2, by = .1))
lm_ridge_best <- as.numeric(names(which.min(out$GCV)))
my_lambda
lm_ridge_best
set.seed(2)
X <- matrix(rnorm(1000 * 5), ncol = 5)
X[ ,1] <- X[ ,1] * 0.001 + X[ ,2] * (1 - 0.001)
beta <- c(1, rep(0, 5 - 1))
set.seed(1)
y <- X %*% beta + rnorm(nrow(X))
data <- data.frame(X, y)
my_lambda <- best_lambda(formula = y ~ ., lambda_list = 10^seq(-2, 2, by = .1),
data = data, intercept = FALSE)
# Use lm.ridge from MASS library as the reference
lm_ridge <- lm.ridge(y ~. -1, data, lambda =  10^seq(-2, 2, by = .1))
lm_ridge_best <- as.numeric(names(which.min(lm_ridge$GCV)))
lm_ridge_best
my_lambda
library(bis557)
